{
    "error": false,
    "course": {
        "id": 2501,
        "subject": "MATH",
        "code": "6380O",
        "name": "Deep Learning: Toward Deeper Understanding",
        "description": "This course is inspired by Stanford Stats 385, Theories of Deep Learning, taught by Prof. Dave Donoho, Dr. Hatef Monajemi and Mr. Vardan Papyan. The aim of this course is to be provide graduate students who are interested in deep learning a variety of mathematical and theoretical understanding of neural networks which are currently available in research, in addition to some preliminary tutorials. Students with mathematical maturity on approximation theory, optimization, and statistics will be helpful.",
        "categories": [],
        "website": null,
        "credits": 3,
        "semesters": [
            1910,
            1730
        ],
        "prerequisites": "",
        "corequisites": "",
        "exclusions": "",
        "rating_content": 4,
        "rating_teaching": 1.5,
        "rating_grading": 4.5,
        "rating_workload": 3.5,
        "review_count": 2,
        "single_review": false,
        "enrollment_status": 0,
        "is_favourited": false,
        "is_subscribed": false,
        "user_review_hash": "",
        "contributor_has_more": false,
        "instructors": [
            {
                "id": 1021,
                "name": "YAO, Yuan",
                "count": 2
            }
        ]
    },
    "reviews": [
        {
            "hash": "FV3qOifBvAXjBuJX7vK3aALjpKrlnrdu",
            "semester": "2019-20 Fall",
            "instructors": [
                {
                    "id": 1021,
                    "name": "YAO, Yuan",
                    "rating": 1
                }
            ],
            "is_author": false,
            "author": "YANG Qing",
            "date": "Nov 29, 2020",
            "title": "Deep Learning",
            "comment_content": "Just follow the Stanford deep learning course, the same structure, the same pace, and even the same materials. If you really want to learn DL staff, just google and look some videos, then it can be the same as taking the course",
            "comment_teaching": "Just read the materials and play videos. Professor is quite busy, but the invited talks are interesting. I just like the invited talk of this course, some could be helpful and cutting edge knowledge.",
            "comment_grading": "Grading is not bad. But cannot learn much",
            "comment_workload": "Quite light, just team work assignment. And even if you did not learn that course, you can finish that by some packages.",
            "rating_content": 3,
            "rating_teaching": 2,
            "rating_grading": 5,
            "rating_workload": 4,
            "has_midterm": false,
            "has_final": false,
            "has_quiz": false,
            "has_assignment": false,
            "has_essay": false,
            "has_project": true,
            "has_attendance": false,
            "has_reading": false,
            "has_presentation": true,
            "upvote_count": 0,
            "vote_count": 0,
            "voted": false,
            "is_upvote": false,
            "comment_count": 0,
            "attachments": []
        },
        {
            "hash": "NazBUdNq8HuEGyD7Iw6LLJ6k3e4Ck332",
            "semester": "2019-20 Fall",
            "instructors": [
                {
                    "id": 1021,
                    "name": "YAO, Yuan",
                    "rating": 1
                }
            ],
            "is_author": false,
            "author": "mhear",
            "date": "Feb 20, 2020",
            "title": "",
            "comment_content": "The content is mostly good and spot on a number of interesting researches, but it is not organized, and thus not for someone without research experience in the most recent ML. Actually, this course is more a seminar, and I would rather call it a course of &quot;Review on Selected Papers from Past NeuIPS/ICML/ICLRs&quot;. The first half of the course seems more on Prof. Yao's interests, on scattering networks, robustness, etc. While, the second part is on typical ML theory issues, such as optimization, loss landscape, generalization, etc.",
            "comment_teaching": "There's basically no teaching. On 3/4 of the course Prof. Yao was playing videos of other people instead of giving lecture by himself.",
            "comment_grading": "The grade is fine.",
            "comment_workload": "It would take a lot of time if you really want to fully understand everything (which is more about math), but the project itself has nothing to do with the lectures and should be easy for someone with moderate DL research/engineering experiences.",
            "rating_content": 5,
            "rating_teaching": 1,
            "rating_grading": 4,
            "rating_workload": 3,
            "has_midterm": false,
            "has_final": false,
            "has_quiz": false,
            "has_assignment": true,
            "has_essay": false,
            "has_project": true,
            "has_attendance": false,
            "has_reading": false,
            "has_presentation": false,
            "upvote_count": 0,
            "vote_count": 0,
            "voted": false,
            "is_upvote": false,
            "comment_count": 0,
            "attachments": []
        }
    ],
    "composer": []
}