{
    "error": false,
    "course": {
        "id": 2495,
        "subject": "MATH",
        "code": "4432",
        "name": "Statistical Machine Learning",
        "description": "This course provides students with an extensive exposure to the elements of statistical machine learning in supervised and unsupervised learning with real world datasets. Topics include regression, classification, resampling methods, model assessment, model selection, regularization, nonparametric models, boosting, ensemble methods, random forests, kernel methods, support vector machines, neural networks, and some standard techniques in unsupervised learning such as clustering and dimensionally reduction. Lab sessions on using R or Python in data analysis with machine learning methods will be conducted in class. Scientific reports and/or poster presentations are required for project evaluations.",
        "categories": [],
        "website": null,
        "credits": 3,
        "semesters": [
            2210,
            2110,
            2010,
            1910,
            1730
        ],
        "prerequisites": "(<a class=\"course-link\" data-subject=\"COMP\" data-code=\"1021\" href=\"/review/COMP1021\" target=\"_blank\">COMP 1021</a> OR <a class=\"course-link\" data-subject=\"COMP\" data-code=\"1022P\" href=\"/review/COMP1022P\" target=\"_blank\">COMP 1022P</a> OR <a class=\"course-link\" data-subject=\"COMP\" data-code=\"1022Q\" href=\"/review/COMP1022Q\" target=\"_blank\">COMP 1022Q</a> (prior to 2020-21)) AND (IEDA 2510 (prior to 2018-19) OR (<a class=\"course-link\" data-subject=\"IEDA\" data-code=\"2520\" href=\"/review/IEDA2520\" target=\"_blank\">IEDA 2520</a> AND <a class=\"course-link\" data-subject=\"IEDA\" data-code=\"2540\" href=\"/review/IEDA2540\" target=\"_blank\">IEDA 2540</a>) OR <a class=\"course-link\" data-subject=\"ISOM\" data-code=\"2500\" href=\"/review/ISOM2500\" target=\"_blank\">ISOM 2500</a> OR <a class=\"course-link\" data-subject=\"LIFS\" data-code=\"3150\" href=\"/review/LIFS3150\" target=\"_blank\">LIFS 3150</a> OR <a class=\"course-link\" data-subject=\"MATH\" data-code=\"2411\" href=\"/review/MATH2411\" target=\"_blank\">MATH 2411</a> OR <a class=\"course-link\" data-subject=\"MATH\" data-code=\"2421\" href=\"/review/MATH2421\" target=\"_blank\">MATH 2421</a> OR <a class=\"course-link\" data-subject=\"MATH\" data-code=\"2431\" href=\"/review/MATH2431\" target=\"_blank\">MATH 2431</a>)",
        "corequisites": "",
        "exclusions": "",
        "rating_content": 4.1,
        "rating_teaching": 3.6,
        "rating_grading": 3.5,
        "rating_workload": 3.2,
        "review_count": 10,
        "single_review": false,
        "enrollment_status": 3,
        "is_favourited": false,
        "is_subscribed": false,
        "user_review_hash": "",
        "contributor_has_more": false,
        "instructors": [
            {
                "id": 1118,
                "name": "YANG, Can",
                "count": 7
            },
            {
                "id": 1021,
                "name": "YAO, Yuan",
                "count": 2
            },
            {
                "id": 1363,
                "name": "CAI, Mingxuan",
                "count": 1
            }
        ]
    },
    "reviews": [
        {
            "hash": "ZpxXFZDjMwQSQKooFhVEknQvhWp2ZVqG",
            "semester": "2019-20 Fall",
            "instructors": [
                {
                    "id": 1118,
                    "name": "YANG, Can",
                    "rating": 1
                },
                {
                    "id": 1363,
                    "name": "CAI, Mingxuan",
                    "rating": 1
                }
            ],
            "is_author": false,
            "author": "jacko",
            "date": "Mar 16, 2020",
            "title": "Good introductory course",
            "comment_content": "1. Introduction (bias-variance trade off, overfitting)<br />2. Linear regression<br />3. Linear classification (LDA, QDA, logistic regression)<br />4. Resampling<br />5. Linear model selection (subset selection, shrinkage) <br />6. Moving beyond linearity (ISLR chapter 7) *<br />7. Tree-based methods<br />8. SVM *<br />9. Unsupervised learning (clustering, EM, PCA)<br />10. Variational inference in deep learning *<br /><br />* certain topics weren't covered due to issues with timing this semester<br /><br />Most of the content is quite standard for intro machine learning courses but prof. Yang also added some topics like coordinate descent, EM algorithm, Fisher information, etc.. Note that this course puts some emphasis on statistics. <br /><br />Most of the material is taken from the books ISLR (Intro to Statistical Learning), ESL (Elements of Statistical Learning), and PRML (Pattern Recognition and Machine Learning).",
            "comment_teaching": "Prof. Yang is very passionate and knowledgeable in regard to the subject matter; all the notes are well prepared and he tries his best to make the material easy to understand without watering down the content. Generally he's not afraid to go in depth with certain topics if he finds it to be important, sometimes he'll even talk about some relevant research literature. <br /><br />You can just skip the lectures and instead read from the textbooks but personally I found the lectures to be quite enjoyable. The tutorials mainly cover the coding stuff so that may be useful for people who skip lectures or those without much coding background.",
            "comment_grading": "Decent grading for a math course I think. I'm not a math student and I didn't put in a lot of effort but I got above mean in the assessments and got a B+ overall which is reasonable.",
            "comment_workload": "Decent workload. If you have some programming background, knowledge in statistics and linear algebra then it's not bad, otherwise you might need to spend more time to learn some things. Overall I'd say it's quite rewarding.<br /><br />There are 3 homework assignments which involve some questions to be done on paper (such as proofs), this accounts for half and the other half would be programming problems (like asking you to implement an algorithm in R/Python for example).<br /><br />There's one project where you had to do some more programming (for us we had to implement EM algorithm) and some other task ask well.<br /><br />The final was just mostly easy problems from ISLR and a problem asking you to derive something using EM.",
            "rating_content": 5,
            "rating_teaching": 5,
            "rating_grading": 4,
            "rating_workload": 4,
            "has_midterm": false,
            "has_final": true,
            "has_quiz": false,
            "has_assignment": true,
            "has_essay": false,
            "has_project": true,
            "has_attendance": false,
            "has_reading": false,
            "has_presentation": false,
            "upvote_count": 6,
            "vote_count": 6,
            "voted": false,
            "is_upvote": false,
            "comment_count": 0,
            "attachments": []
        },
        {
            "hash": "mXVYKG8D2nx7ShJuxtr46nlZRWT9h5zl",
            "semester": "2020-21 Fall",
            "instructors": [
                {
                    "id": 1118,
                    "name": "YANG, Can",
                    "rating": 1
                }
            ],
            "is_author": false,
            "author": "USTAsiaNo1",
            "date": "Jan 01, 2021",
            "title": "comprehensive introduction of statistical learning with depth",
            "comment_content": "- Content<br /><br />Introduction to Statistical machine learning.<br />Linear Regression.<br />Classification.<br />Resampling.<br />Linear Model Selection.<br />Moving Beyond Linearity.<br />Tree-based Methods.<br />Support Vector Machine. &lt; not covered at all<br />EM algorithm and clustering<br />Variational Inference in Deep learning (optional). &lt; not covered at all<br /><br />- Comment<br /><br />I think It covers a great variety of contents in which you can easily go further in deeper in the future.<br /><br />However, indeed, as you can see, there is NO coverage of Deep-Learning, like CNN, RNN.........<br /><br />Still, this course is fairly deep and mathematics-orientated in the content it discussed.<br /><br />SO, this course provides:<br />Fundamentals in ML with a detailed, conceptual, statistical approach (O)<br />Advanced contents in ML and Deep Learning (X)<br /><br />Don't expect the wrong thing and go to COMP one for some more advanced ML thing =)<br /><br />- About &quot;Statistical&quot;<br /><br />Um, TBH, it is not really statistical, you don't need to use knowledge from probability or inference(2411/3423) intensively<br />Like, the professor did say something about LRT (likelihood ratio test), Fisher Information, asymptotic estimator in class, it won't be tested in the exam anyway<br />You can definitely take this course with elementary statistics and intermediate-to-advance calculus <br /><br />Still, it is not fully free-of-statistics<br />Like Bayes's approach is expected to solve some particular problem, I just want to clarify that it is not THAT statistical as you might imagine based on the course title<br /><br />(side-story) Calculus is more repetitively used in this course than Statistics lol<br />You can think about it, you need calculus to do optimisation instead of statistics lol<br />When you do OLS, you need differentiation more lol<br /><br />(side-side-story) If you know matrix calculus, you can have some edge over others, you can also think of it: ML = optimization of function with matrix<br /><br />- About programming<br /><br />R and python <br />the project REQUIRES you to use any of the above to do empirical analysis, you better know something about R or python before taking this<br /><br />- About the reference book<br /><br />ISLR 7th edition<br /><br />This book covers maybe 60% content, this book is quite introductory, which the professor adds some advanced content that is not covered in the book into the course<br /><br />You can read the book to get a brief image of the level of this course, what you will learn is at least as hard as this book =)",
            "comment_teaching": "- Comment<br /><br />1. Professor gives detailed explanation <br />Sometimes, I even think it is too detail. <br />Professor would repeat something he considered important again and again, you might think it is boring but on the other side he indeed tried his best to tell everything important to you.<br /><br />SO, I would say you can get every important points he said<br /><br />2. He loves hard-writing and it is good<br />I personally think his explanation which he writes everything on a A4 paper and explain it step-by-step is fascinating<br />Every steps are clearly illustrated, it is much better than his slides, which is quite jumpy and hard-to-follow <br /><br />SO, watch the video / attend the lesson to see how he explains everything step-by-step instead of reading slides<br /><br />BUT, if you really want to read slides or something, read the book, a famous book in statistical learning: ISLR, just google it, it is free and MUCH better than the slides, at least I found it much easier to follow. Yet, as mentioned in the content part, some advanced topic is not covered in that book, so you might need find other materials... (maybe Element of Statistical Learning, just a suggestion)",
            "comment_grading": "premise to know:<br />&gt; Final score is NOT disclosed!<br />&gt; (maybe) Grading Scheme is NOT disclosed!<br /><br />- Grading Scheme<br /><br />Um..<br />I searched for 10 minutes and cannot find the grading scheme in canvas<br />I really don't think he had mentioned it at anytime in the course<br /><br />- Statistics<br /><br />me: <br />Assignment 1: 10/10<br />Assignment 2: 9/10<br />Assignment 3: 8/10<br />Final: NOT disclosed<br />Project: 9/10<br /><br />grade: A-<br /><br />mean:<br />Assignment 1: 8.6/10<br />Assignment 2: 9.6/10<br />Assignment 3: 9.4/10<br />Final: NOT disclosed<br />Project: 8.2/10<br /><br />- Conclusion<br /><br />When I don't know the grading scheme and final score, I cannot really tell any useful information.<br /><br />At least, for what I see, i think it is fairly good<br /><br />Still, I have to give a C since I really don't know the key information of the grading of this course<br /><br />** it seems like cinder found the grading scheme, please check his/her review for reference. I will remain my C in this section since I cannot confirm if his/her information is correct or not as I still cannot find the scheme myself, lol.",
            "comment_workload": "- Comment<br /><br />I think the workload is fair for a course in mathematics and in machine learning <br /><br />1. Assignment<br />Standard question, 90% is from ISLR with some extra coding problem, 1~2 days/each is ok<br />2. Project (individual)<br />I think it is quite hard, it just gives you a dataset, you can use any method you learnt to process it and draw conclusion, it is too free and you have to be creative and good at blowing water to finish it<br />3. Exam<br />Fairly hard, quite conceptual, no quantitative question",
            "rating_content": 5,
            "rating_teaching": 5,
            "rating_grading": 3,
            "rating_workload": 4,
            "has_midterm": false,
            "has_final": true,
            "has_quiz": false,
            "has_assignment": true,
            "has_essay": false,
            "has_project": true,
            "has_attendance": false,
            "has_reading": false,
            "has_presentation": false,
            "upvote_count": 5,
            "vote_count": 5,
            "voted": false,
            "is_upvote": false,
            "comment_count": 1,
            "attachments": []
        },
        {
            "hash": "G5eGU4kNqJubxl0rboWoV6vDBJiXJVJf",
            "semester": "2017-18 Spring",
            "instructors": [
                {
                    "id": 1021,
                    "name": "YAO, Yuan",
                    "rating": 0
                }
            ],
            "is_author": false,
            "author": "gossipgirl",
            "date": "Jun 04, 2018",
            "title": "Worst course at UST - DO NOT EVEN THINK ABOUT IT",
            "comment_content": "Standard classification, deep learning, clustering techniques. All standard material covered by CS courses. This course is pathetic in teaching style and not recommended at all. If this is a requirement, try and replace it by COMP4331/COMP4211. <br /><br />A lot of courses have harsh grading with some objective reason. This course is full of BS.",
            "comment_teaching": "Just goes over slides with a lot of math. no relevance to projects or good discussion. <br />You're much better off taking the machine learning course from CS dept or online courses. <br /><br />The professor has no idea whatsoever of how to teach a class. No idea of how to teach/explain/give assignments or grade them. Disgusting. <br /><br />A lot of courses have harsh grading with some objective reason. This course is full of BS. <br /><br />The teaching deserves an F.",
            "comment_grading": "20% homework<br />80% projects<br /><br />Complete in-transparency about grading - haphazard way of grading with no real concrete measure. Projects are graded by peer review. Rules change overnight. Absolutely nothing is made clear to class and grade seems like blackbox. <br /><br />The grading heavily depends on peer voting for projects. This is completely manipulated as students (mostly local) team up and vote for each other. It makes no sense whatsoever. At the end the useless professor says you got less than median votes and hence you get a C in the entire course, no matter how good your work was. <br /><br />A lot of courses have harsh grading with some objective reason. This course is full of BS.<br /><br /> The grading is taken very lightly by the faculty. <br /><br />The grading deserves an F.",
            "comment_workload": "Homeworks every week. 3 projects over time during semester. There is no reason to take this course. Its taught like a joke.<br /><br />A lot of courses have harsh grading with some objective reason. This course is full of BS.",
            "rating_content": 1,
            "rating_teaching": 1,
            "rating_grading": 1,
            "rating_workload": 1,
            "has_midterm": false,
            "has_final": false,
            "has_quiz": false,
            "has_assignment": true,
            "has_essay": false,
            "has_project": true,
            "has_attendance": false,
            "has_reading": false,
            "has_presentation": false,
            "upvote_count": 2,
            "vote_count": 3,
            "voted": false,
            "is_upvote": false,
            "comment_count": 1,
            "attachments": []
        },
        {
            "hash": "M1o89zwbo8mUTbwsldaUJfc5cL16cnpS",
            "semester": "2022-23 Spring",
            "instructors": [
                {
                    "id": 1118,
                    "name": "YANG, Can",
                    "rating": 1
                }
            ],
            "is_author": false,
            "author": "Siran",
            "date": "May 16, 2023",
            "title": "Not Bad, Not Good",
            "comment_content": "Includes mainstream statistical knowledge as well as machine learning algorithms (KNN/QDA/Random Forest/Decision Trees/EM algorithms) and will spend a lot of time on mathematical knowledge and less time on code instruction.",
            "comment_teaching": "Very logical, but will spend a lot of time on the derivation process.",
            "comment_grading": "Assignments are given good marks, basically unconventional and basically high marks will be given, but!!! I don't know the score of the final exam yet.",
            "comment_workload": "Four assignments with textbook topics and additional questions, all of which require writing code. Some are easy and some are hard, but the difficulty is basically normally distributed",
            "rating_content": 4,
            "rating_teaching": 4,
            "rating_grading": 4,
            "rating_workload": 4,
            "has_midterm": false,
            "has_final": true,
            "has_quiz": false,
            "has_assignment": true,
            "has_essay": false,
            "has_project": false,
            "has_attendance": false,
            "has_reading": false,
            "has_presentation": false,
            "upvote_count": 0,
            "vote_count": 0,
            "voted": false,
            "is_upvote": false,
            "comment_count": 0,
            "attachments": []
        },
        {
            "hash": "Qck0eh1P537bk50lIYQ1YT5e8yMNwduU",
            "semester": "2022-23 Spring",
            "instructors": [
                {
                    "id": 1118,
                    "name": "YANG, Can",
                    "rating": 1
                }
            ],
            "is_author": false,
            "author": "Ming1203",
            "date": "Apr 28, 2023",
            "title": "",
            "comment_content": "[Same as MSBD 5013] This course contains Linear models, Classification, Resampling, Model selection and Regularization, Algorithm, and Tree-based methods. The professor will teach both maths and codes.",
            "comment_teaching": "He has his own story, and each class he can form a whole story. This is good to digest and learn something from a statistical perspective. The accent is not bad but may have weird pronunciations for certain words.",
            "comment_grading": "Very good grading. If the class size is not big he will not curve the grade.",
            "comment_workload": "4 assignments with both math questions and programming (with R) questions. Not that easy but can be achieved in ~2h.",
            "rating_content": 5,
            "rating_teaching": 5,
            "rating_grading": 5,
            "rating_workload": 3,
            "has_midterm": false,
            "has_final": true,
            "has_quiz": false,
            "has_assignment": true,
            "has_essay": false,
            "has_project": false,
            "has_attendance": false,
            "has_reading": false,
            "has_presentation": false,
            "upvote_count": 0,
            "vote_count": 0,
            "voted": false,
            "is_upvote": false,
            "comment_count": 0,
            "attachments": []
        },
        {
            "hash": "lqHThrckO8gdeEKUgCduMAnaklMHUPOu",
            "semester": "2021-22 Fall",
            "instructors": [
                {
                    "id": 1118,
                    "name": "YANG, Can",
                    "rating": 1
                }
            ],
            "is_author": false,
            "author": "lyzzzz",
            "date": "Jan 26, 2022",
            "title": "Good intro course for stat ml",
            "comment_content": "Linear regression, classification, Ridge, LASSO, Trees, EM algorithm...<br /><br />I would give content a B since the course covers smaller than expected. I have no idea",
            "comment_teaching": "To be honest, it is not easy to follow the professor in the class since he uses white paper and visualizer to derive mathematical stuff. Once you get lost, you will never catch up lol<br /><br />However, if you watch the recording at a 3x playback speed, it is quite enjoyable and you can find a clear logic as well as the inspiration ideas behind each model.",
            "comment_grading": "4 Assignments and one Final.<br /><br />Got nearly full in the assignments but final grades are not public.<br /><br />Final exam is at a normal level (if you really understand). I think I did all questions and (may) got 90+<br /><br />Professor is a nice guy though.<br />Grade: A+",
            "comment_workload": "Not high but also requires some effort. <br /><br />You need to write R code in the coding part of the assignment.",
            "rating_content": 4,
            "rating_teaching": 4,
            "rating_grading": 5,
            "rating_workload": 5,
            "has_midterm": false,
            "has_final": true,
            "has_quiz": false,
            "has_assignment": true,
            "has_essay": false,
            "has_project": false,
            "has_attendance": false,
            "has_reading": false,
            "has_presentation": false,
            "upvote_count": 0,
            "vote_count": 0,
            "voted": false,
            "is_upvote": false,
            "comment_count": 0,
            "attachments": []
        },
        {
            "hash": "ahWNfhH6QGPgKRbT26RqOptHPKYRgmvC",
            "semester": "2021-22 Fall",
            "instructors": [
                {
                    "id": 1118,
                    "name": "YANG, Can",
                    "rating": 1
                }
            ],
            "is_author": false,
            "author": "Squidgy",
            "date": "Dec 26, 2021",
            "title": "",
            "comment_content": "Linear regression<br />Classification<br />Some Tree based method<br />Gradient method/ Newton's method<br />EM algorithm",
            "comment_teaching": "A little bit YU Chi Wai teaching style, but a better version. <br />I did find out his course is quite interesting, and would give you a better idea of what is going to be examined in the exam. However, you better read the textbook before the course or else it's easy to get lost during his teaching. Most of the content in the exam may be covered in his writing notes, but not in the textbook. So rip if you are only a textbook reader.",
            "comment_grading": "Professor claimed that he will give everyone at least B range if no plagiarism happened. And probably 30% A range.<br />But he disclosed nothing after final, and I got B+. So no idea about anything.",
            "comment_workload": "The coding question in each assignment may take some time.<br />4 assignments and final exam.",
            "rating_content": 4,
            "rating_teaching": 4,
            "rating_grading": 3,
            "rating_workload": 3,
            "has_midterm": false,
            "has_final": true,
            "has_quiz": false,
            "has_assignment": true,
            "has_essay": false,
            "has_project": false,
            "has_attendance": false,
            "has_reading": false,
            "has_presentation": false,
            "upvote_count": 0,
            "vote_count": 0,
            "voted": false,
            "is_upvote": false,
            "comment_count": 0,
            "attachments": []
        },
        {
            "hash": "S8PJXgDWr9XLvGW6i1VFtKHGbxvOWTLu",
            "semester": "2017-18 Spring",
            "instructors": [
                {
                    "id": 1021,
                    "name": "YAO, Yuan",
                    "rating": 1
                }
            ],
            "is_author": false,
            "author": "owenkit",
            "date": "Nov 01, 2018",
            "title": "If you are a math/stat student, this is a good course for you to learn ML and its theory",
            "comment_content": "It is a basic introduction to ML. Although some are complaining that it is mathematically heavy, it is not, as you can see from the course title that who is the target audience for the course. You may not expect to learn in-depth mathematical proof there as well.",
            "comment_teaching": "He just repeats everything in the book and reads every word in the lecture notes once. It is very boring in the lesson. Just read the content at home by yourself is ok. However, his knowledge in ML must give you a help if you ask him in person after class.",
            "comment_grading": "The grading scheme is quite strange and it is decided quite last minute in the whole semester. It also involve peer evaluation as well. However, if you do everything and put some effort in it, your grade will not be bad. He is quite generous in grading I think.",
            "comment_workload": "The workload is quite heavy. There is weekly homework for you to practice the coding part of every topic. But don't worry, 95% of the code you need is taught in the book. Besides that, there are three projects which account for the majority of your final grade. The projects require a poster to represent your results which I think it takes you some time to do as well. For the coding homework, you will get the marks if you hand in and there are lots of sources outside...",
            "rating_content": 4,
            "rating_teaching": 1,
            "rating_grading": 4,
            "rating_workload": 3,
            "has_midterm": false,
            "has_final": false,
            "has_quiz": false,
            "has_assignment": true,
            "has_essay": false,
            "has_project": true,
            "has_attendance": false,
            "has_reading": false,
            "has_presentation": false,
            "upvote_count": 2,
            "vote_count": 4,
            "voted": false,
            "is_upvote": false,
            "comment_count": 0,
            "attachments": []
        },
        {
            "hash": "96JG6Jsg7ALGVc2GdkqgVPrQX7ktetHd",
            "semester": "2020-21 Fall",
            "instructors": [
                {
                    "id": 1118,
                    "name": "YANG, Can",
                    "rating": 1
                }
            ],
            "is_author": false,
            "author": "Cinder",
            "date": "Jan 24, 2021",
            "title": "good content, good grade, professor is a nice guy, but both the teaching &amp; assignments need improvement",
            "comment_content": "Introduction to Statistical machine learning.<br />Linear Regression.<br />Classification.<br />Resampling.<br />Linear Model Selection.<br />Moving Beyond Linearity.<br />Tree-based Methods.<br />Support Vector Machine.<br />EM algorithm and clustering",
            "comment_teaching": "Prof. Yang is a nice guy who is very patient. He will answer all questions in details during the class. However, he seems like a beginner in teaching. He spent most of the time in deriving the formula on the paper which makes the course boring and hard to follow. (Listeners could only copy all the notes down and don't have pretty much time to understand.) After most of his lectures, I could not even remember what he taught in the past 1.2 hours, but only got pages of notes. WHEREAS HALF OF THE EXAM QUESTIONS COMES FROM HIS WRITING NOTES! Don't be lazy to write down everything. <br /><br />The textbook is, on the other hand, pretty good. You can easily understand most of the contents by going through the textbook book.&nbsp;&nbsp;Seems like Prof. Yang made some effort to summarize the most important things in the textbook (as well as some extra important content like EM algorithm) and tried to deliver them clearly in the class, but what students' experience was not good.",
            "comment_grading": "Pretty good grading. But it all depends on the final.<br /><br />Since the assignments are all from the textbook with answers online, most of the students will get full marks. Also, the project's grading is not that serious. We all get like 8/9 out of 10.<br /><br />The grading scheme is:<br />30 percent assignment (3 assignments in total)<br />10 percent course project<br />60 percent final.<br /><br />Personal result:<br />30/30 in assignment<br />9/10 in the course project<br />final score doesn't know (But I thought I did it pretty well. I finished 7 questions (out of 8). The final is more difficult than the sample paper but doable.<br /><br />Final grade: A+ <br /><br />Even though only around 50 students took this course in 2020 fall but I've heard many of my friends got A and A+. I am pretty sure that the A range is nearly 30 percent. Compared to most of the math courses in UST, definitely a good grade one.",
            "comment_workload": "Overall not much workload. 3 assignments with most of the questions come from the textbook. You can find the answers easily online. One course project which I could not say well-designed. <br /><br />Assignments:<br />Most of the questions just come from the textbook and personally I did not found them very helpful. The extra coding questions are not bad, sometimes maybe too much of tired/boring works included but the overall experience is good. I enhanced my understanding with the help of the coding questions.&nbsp;&nbsp;&nbsp;<br /><br />Project:<br />The course project is terrible. We were asked to apply whatever methods we learnt on a given data set and do prediction based on it. The problem is we don't have any clearly grading scheme released. Since the only thing we can evaluate our projects is the r-square score, we could only do as much as we can and keep trying until the last minutes. Also, the ddl is in the final period, I believed most of the students wasted a lot of time only to improve his/her r-square score by 0.05. <br /><br />The most disappointing part about the project is the grade. TA&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;did not go through the project report seriously and most of the students got similar scores, like 8/9 out of 10, make this course &quot;all in final&quot;.",
            "rating_content": 5,
            "rating_teaching": 4,
            "rating_grading": 5,
            "rating_workload": 4,
            "has_midterm": false,
            "has_final": true,
            "has_quiz": false,
            "has_assignment": true,
            "has_essay": false,
            "has_project": true,
            "has_attendance": false,
            "has_reading": false,
            "has_presentation": false,
            "upvote_count": 0,
            "vote_count": 1,
            "voted": false,
            "is_upvote": false,
            "comment_count": 0,
            "attachments": []
        },
        {
            "hash": "VRyPmSB101uBO3Nwv0d9RaElJwxy4jo1",
            "semester": "2017-18 Spring",
            "instructors": [],
            "is_author": false,
            "author": "abcbca",
            "date": "Jun 12, 2018",
            "title": "Everything comes short, sudden and tight.",
            "comment_content": "The content of the course can be divided into two main categories - supervised and unsupervised learning.<br /><br />In the lecture notes, you may see the models are introduced one by one, which makes student clear and know what they are learning in the topic. This is the best thing in this course.<br /><br />But the content of the lecture notes is quite mathematical and theoretical, it is actually super difficult for ML beginners to catch up and understand the materials.",
            "comment_teaching": "The teaching is actually nothing special. The instructor just repeats the thing in the lecture notes and speak in a flat tone which may make students feel bored.(Initially there were students queuing for the course but after add-drop period, there were only 35/50 in the class.) Better do some self-study by reading the textbook and the notes.",
            "comment_grading": "To be honest, the grading scheme is very non-transparent, which accounts for the &quot;worst comment&quot; in this course. <br /><br />There is even a student asking for the grading scheme on the online forum in the mid of the semester.<br /><br />The grading scheme is finally announced in April, with 20-20-20-40 for the weekly homework, 1st mini project, 2nd mini project and the final project. The grading criteria for the projects is some kind of strange, for example, the 2nd mini-project is mainly consisted of the ranking in the Kaggle online contest(range from 1, 2 and 3 grade points) and the voting from other students(1 vote counts for 1 grade point), weird enough huh?<br /><br />But wait, this is not even the final grading scheme. After the final projects are graded, there is an announcement from the instructor saying that there would be 10%(finally it was 6%) extra marks if you guys can do a review for all projects they have voted before and post the review on the online forum. He announced it in a sudden on 2 Jun and the deadline was 5 Jun! This makes the grading scheme quite unfair because the semester comes to the end and everybody is enjoying their vacation, how come they have time to prepare for your bonus task?<br /><br />After the grades have been released, the instructor informed us the distribution of the grades - A: 35%, B: 38%, C: 15%, and F:6%. Oh my god, there isn't even a D! But the grading is quite good as there are 73% of the students got a satisfactory grade, but the grading would be much fairer if there was no extra review.",
            "comment_workload": "For me, it is super harsh.<br /><br />If you haven't even learnt R/Python before, you may not want to take the course because this is the basic requirement of the course.<br /><br />Homework deadlines every week, two mini-projects at the start of Mar and Apr and dead after two weeks, and a final project after the end of the course and dead in-between final exams!",
            "rating_content": 4,
            "rating_teaching": 3,
            "rating_grading": 1,
            "rating_workload": 1,
            "has_midterm": false,
            "has_final": false,
            "has_quiz": false,
            "has_assignment": true,
            "has_essay": false,
            "has_project": true,
            "has_attendance": false,
            "has_reading": false,
            "has_presentation": false,
            "upvote_count": 0,
            "vote_count": 4,
            "voted": false,
            "is_upvote": false,
            "comment_count": 1,
            "attachments": []
        }
    ],
    "composer": []
}